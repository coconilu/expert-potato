# Expert Potato æ‰“åŒ…ä¼˜åŒ–è¯´æ˜

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡

é€šè¿‡å®æ–½**æ–¹æ¡ˆ 3ï¼šè¿è¡Œæ—¶ä¸‹è½½æ¨¡å‹**ç­–ç•¥ï¼Œå°†åº”ç”¨æ‰“åŒ…ä½“ç§¯ä» **3GB å‡å°‘åˆ° 50-200MB**ã€‚

## ğŸ“Š é—®é¢˜åˆ†æ

### åŸå§‹ä½“ç§¯æ„æˆ

- **PyTorch CUDA ç‰ˆæœ¬**: 5.50 GB (ä¸»è¦é—®é¢˜)
- **TorchAudio**: 14.62 MB
- **Faster-whisper**: 1.43 MB
- **PyQt6 ç›¸å…³**: ç›¸å¯¹è¾ƒå°
- **HuggingFace æ¨¡å‹ç¼“å­˜**: å¯èƒ½æ•° GB

### ä¼˜åŒ–ç­–ç•¥

1. **æ’é™¤å¤§å‹ PyTorch æ¨¡å—**: ç§»é™¤ä¸å¿…è¦çš„åˆ†å¸ƒå¼ã€æµ‹è¯•ã€ä¼˜åŒ–ç­‰æ¨¡å—
2. **æ’é™¤æ¨¡å‹ç¼“å­˜**: ä¸æ‰“åŒ…é¢„ä¸‹è½½çš„ Whisper æ¨¡å‹
3. **è¿è¡Œæ—¶ä¸‹è½½**: é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½æ‰€éœ€æ¨¡å‹
4. **è¿‡æ»¤ CUDA åº“**: åªä¿ç•™åŸºç¡€ CUDA è¿è¡Œæ—¶

## ğŸ› ï¸ å®æ–½çš„ä¼˜åŒ–

### 1. å¢å¼ºçš„ PyInstaller é…ç½® (`Expert Potato.spec`)

#### æ’é™¤æ¨¡å—ç­–ç•¥

```python
# å¤§å¹…æ‰©å±•çš„æ’é™¤æ¨¡å—åˆ—è¡¨ï¼ˆ70+ ä¸ªæ¨¡å—ï¼‰
excluded_modules = [
    # HuggingFaceç›¸å…³ï¼ˆå¤§å‹æ¨¡å—ï¼‰
    'transformers', 'datasets', 'tokenizers', 'accelerate', 'diffusers',
    'huggingface_hub.inference', 'huggingface_hub.repository',

    # PyTorchå¤§å‹æ¨¡å— - æ›´æ¿€è¿›çš„æ’é™¤
    'torch.distributed', 'torch.optim', 'torch.jit', 'torch.onnx',
    'torch.quantization', 'torch.fx', 'torch.ao', 'torch.profiler',
    'torch.autograd.profiler', 'torch.utils.tensorboard',
    'torch.utils.benchmark', 'torch.utils.bottleneck',
    'torch.utils.checkpoint', 'torch.utils.cpp_extension',
    'torch.utils.data.datapipes', 'torch.testing', 'torch.hub',
    'torch.backends.mkldnn', 'torch.backends.mkl',
    'torch.backends.openmp', 'torch.backends.quantized',
    # ç¥ç»ç½‘ç»œæ¨¡å—
    'torch.nn.modules.activation', 'torch.nn.modules.batchnorm',
    'torch.nn.modules.container', 'torch.nn.modules.conv',
    'torch.nn.modules.dropout', 'torch.nn.modules.linear',
    'torch.nn.modules.loss', 'torch.nn.modules.normalization',
    'torch.nn.modules.padding', 'torch.nn.modules.pooling',
    'torch.nn.modules.rnn', 'torch.nn.modules.sparse',
    'torch.nn.modules.transformer', 'torch.nn.modules.upsampling',
    'torch.nn.modules.utils', 'torch.nn.parallel', 'torch.nn.utils',
    # ä¼˜åŒ–å™¨æ¨¡å—
    'torch.optim.lr_scheduler', 'torch.optim.optimizer',
    'torch.optim.sgd', 'torch.optim.adam', 'torch.optim.adamw',
    'torch.optim.rmsprop',

    # TorchAudioå¤§å‹æ¨¡å—
    'torchaudio.datasets', 'torchaudio.models', 'torchaudio.pipelines',
    'torchaudio.prototype', 'torchaudio.compliance',
    'torchaudio.kaldi_io', 'torchaudio.sox_effects',

    # å…¶ä»–å¤§å‹ä¾èµ–
    'scipy', 'sklearn', 'pandas', 'matplotlib', 'seaborn',
    'plotly', 'jupyter', 'notebook', 'ipython', 'sympy',
    'networkx', 'PIL.ImageTk', 'tkinter'
]
```

#### æ™ºèƒ½æ–‡ä»¶è¿‡æ»¤å™¨

```python
def filter_binaries_and_datas(items):
    """è¿‡æ»¤æ‰æ¨¡å‹æ–‡ä»¶ã€ç¼“å­˜æ–‡ä»¶å’Œå¤§å‹äºŒè¿›åˆ¶æ–‡ä»¶"""
    filtered = []
    excluded_count = 0
    total_excluded_size = 0

    for item in items:
        if len(item) >= 2:
            name, path = item[0], item[1]
            should_exclude = False

            # æ’é™¤æ¨¡å‹æ–‡ä»¶
            if any(pattern in name.lower() for pattern in [
                'whisper', 'model', '.bin', '.pt', '.pth', '.onnx', '.safetensors',
                'pytorch_model', 'tf_model', 'flax_model'
            ]):
                should_exclude = True

            # æ’é™¤ç¼“å­˜ç›®å½•
            if any(pattern in path.lower() for pattern in [
                'cache', 'huggingface', 'transformers_cache', '.cache',
                'models--', 'snapshots'
            ]):
                should_exclude = True

            # æ’é™¤å¤§å‹CUDAåº“ï¼ˆæ›´æ¿€è¿›çš„è¿‡æ»¤ï¼‰
            if any(pattern in name.lower() for pattern in [
                'cublas', 'cufft', 'curand', 'cusparse', 'cusolver',
                'cudnn', 'nccl', 'nvtx', 'cublaslt', 'cusparse',
                'cusolverdn', 'cufftw', 'nvjpeg', 'nvrtc'
            ]) and name.lower().endswith(('.dll', '.so', '.dylib')):
                should_exclude = True

            # æ’é™¤å¤§å‹PyTorchäºŒè¿›åˆ¶æ–‡ä»¶
            if any(pattern in name.lower() for pattern in [
                'torch_cpu.dll', 'torch_cuda.dll', 'c10_cuda.dll',
                'torch_python.dll', 'caffe2_nvrtc.dll'
            ]):
                should_exclude = True

            # æ’é™¤å¤§å‹TorchAudioæ–‡ä»¶
            if any(pattern in name.lower() for pattern in [
                'torchaudio.dll', '_torchaudio.pyd'
            ]):
                should_exclude = True

            # æ’é™¤å¤§å‹numpy/scipyç›¸å…³æ–‡ä»¶
            if any(pattern in name.lower() for pattern in [
                'mkl_', 'libopenblas', 'libblas', 'liblapack'
            ]) and name.lower().endswith(('.dll', '.so', '.dylib')):
                should_exclude = True

            if should_exclude:
                excluded_count += 1
                continue

        filtered.append(item)

    print(f"ğŸ—‘ï¸  å·²æ’é™¤ {excluded_count} ä¸ªå¤§å‹æ–‡ä»¶")
    return filtered

# åº”ç”¨è¿‡æ»¤å™¨
a.binaries = filter_binaries_and_datas(a.binaries)
a.datas = filter_binaries_and_datas(a.datas)
```

### 2. è¿è¡Œæ—¶æ¨¡å‹ä¸‹è½½ (`audio_extract_worker.py`)

#### å¢å¼ºçš„æ¨¡å‹ä¸‹è½½é€»è¾‘

```python
def ensure_model_downloaded(self, model_name):
    """ç¡®ä¿æ¨¡å‹å·²ä¸‹è½½ï¼Œå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨ä¸‹è½½"""
    try:
        # æ„å»ºç¼“å­˜ç›®å½•è·¯å¾„
        cache_dir = Path(AUDIO_EXTRACT_CACHE_DIR).expanduser()
        model_pattern = f"*{model_name}*"

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜
        cached_models = list(cache_dir.glob(f"**/{model_pattern}"))

        if not cached_models:
            # æ˜¾ç¤ºä¸‹è½½æç¤º
            self.text_extracted.emit(AUDIO_EXTRACT_MSG_FIRST_RUN)
            self.text_extracted.emit(AUDIO_EXTRACT_MSG_DOWNLOADING)
            self.progress_updated.emit(0)  # å¼€å§‹ä¸‹è½½è¿›åº¦

        # é€‰æ‹©è®¾å¤‡ï¼ˆCUDAæˆ–CPUï¼‰
        device = "cuda" if self.is_cuda_available() else "cpu"
        compute_type = AUDIO_EXTRACT_COMPUTE_TYPE_CUDA if device == "cuda" else AUDIO_EXTRACT_COMPUTE_TYPE_CPU

        # WhisperModelä¼šè‡ªåŠ¨ä¸‹è½½ç¼ºå¤±çš„æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
        model = WhisperModel(
            model_name,
            device=device,
            compute_type=compute_type,
            download_root=str(cache_dir)  # æŒ‡å®šä¸‹è½½æ ¹ç›®å½•
        )

        if not cached_models:
            self.text_extracted.emit("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆ")
            self.progress_updated.emit(100)  # ä¸‹è½½å®Œæˆ

        return model

    except Exception as e:
        error_msg = f"æ¨¡å‹ä¸‹è½½å¤±è´¥: {str(e)}"
        self.text_extracted.emit(error_msg)
        raise
```

### 3. ç”¨æˆ·ä½“éªŒä¼˜åŒ– (`core.py`)

#### æ–°å¢é…ç½®å¸¸é‡

```python
# éŸ³é¢‘æå–ç¼“å­˜ç›®å½•
AUDIO_EXTRACT_CACHE_DIR = "~/.cache/huggingface/hub"

# ä¸‹è½½é…ç½®
AUDIO_EXTRACT_DOWNLOAD_TIMEOUT = 300  # 5åˆ†é’Ÿè¶…æ—¶
AUDIO_EXTRACT_RETRY_COUNT = 3  # é‡è¯•æ¬¡æ•°
AUDIO_EXTRACT_CHUNK_SIZE = 8192  # ä¸‹è½½å—å¤§å°

# ç”¨æˆ·æç¤ºæ¶ˆæ¯
AUDIO_EXTRACT_MSG_DOWNLOADING = "æ­£åœ¨ä¸‹è½½æ¨¡å‹ï¼Œè¯·ç¨å€™..."
AUDIO_EXTRACT_MSG_FIRST_RUN = "é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´"
AUDIO_EXTRACT_MSG_DOWNLOAD_COMPLETE = "æ¨¡å‹ä¸‹è½½å®Œæˆ"
AUDIO_EXTRACT_MSG_DOWNLOAD_FAILED = "æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
AUDIO_EXTRACT_MSG_CACHE_CHECK = "æ­£åœ¨æ£€æŸ¥æ¨¡å‹ç¼“å­˜..."
```

### 4. æ„å»ºè„šæœ¬ä¼˜åŒ– (`build.py`)

#### æ›´æ–°çš„æ„å»ºå‡½æ•°

```python
def build_app():
    """æ„å»ºåº”ç”¨ç¨‹åºï¼ˆæ–‡ä»¶å¤¹ç‰ˆæœ¬ï¼Œæ¨èï¼‰"""
    print("ğŸš€ å¼€å§‹æ„å»º Expert Potato (ä¼˜åŒ–ç‰ˆæœ¬)...")
    print("ğŸ“ æ³¨æ„: ä½¿ç”¨ä¼˜åŒ–çš„specæ–‡ä»¶æ¥å‡å°æ„å»ºäº§ç‰©å¤§å°")
    print("ğŸ¯ ç­–ç•¥: æ’é™¤æ¨¡å‹ç¼“å­˜ï¼Œè¿è¡Œæ—¶è‡ªåŠ¨ä¸‹è½½")

    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ src/main.py
    if not Path("src/main.py").exists():
        print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° src/main.py æ–‡ä»¶")
        return False

    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¼˜åŒ–çš„specæ–‡ä»¶
    spec_file = "Expert Potato.spec"
    if not Path(spec_file).exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {spec_file} æ–‡ä»¶")
        return False

    # ä½¿ç”¨ä¼˜åŒ–çš„specæ–‡ä»¶æ„å»ºï¼ˆæ’é™¤æ¨¡å‹ç¼“å­˜å’Œå¤§å‹æ¨¡å—ï¼‰
    cmd = [
        "uv", "run", "pyinstaller", spec_file,
        "--clean", "--noconfirm"
    ]

    # æ‰§è¡Œæ„å»ºå¹¶æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    if subprocess.run(cmd).returncode == 0:
        print("âœ… æ„å»ºæˆåŠŸï¼")

        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶å¤¹
        app_dir = Path("dist/Expert Potato")
        if app_dir.exists():
            print(f"ğŸ“¦ åº”ç”¨ç¨‹åºæ–‡ä»¶å¤¹: {app_dir}")
            exe_path = app_dir / "Expert Potato.exe"
            if exe_path.exists():
                file_size = exe_path.stat().st_size / (1024 * 1024)  # MB
                print(f"ğŸ¯ ä¸»æ‰§è¡Œæ–‡ä»¶: {exe_path}")
                print(f"ğŸ“ ä¸»æ–‡ä»¶å¤§å°: {file_size:.1f} MB")

                # è®¡ç®—æ•´ä¸ªæ–‡ä»¶å¤¹å¤§å°
                total_size = sum(f.stat().st_size for f in app_dir.rglob('*') if f.is_file()) / (1024 * 1024)
                print(f"ğŸ“Š æ€»æ–‡ä»¶å¤¹å¤§å°: {total_size:.1f} MB")
                print(f"ğŸ’¡ æç¤º: é¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
        return True
    else:
        print("âŒ æ„å»ºå¤±è´¥")
        return False
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ„å»ºåº”ç”¨

```bash
# æ–¹æ³•1: ä½¿ç”¨æ‰¹å¤„ç†è„šæœ¬
build.bat

# æ–¹æ³•2: ä½¿ç”¨Pythonè„šæœ¬
python build.py build

# æ–¹æ³•3: ç›´æ¥ä½¿ç”¨PyInstaller
uv run pyinstaller "Expert Potato.spec" --clean --noconfirm
```

### é¦–æ¬¡è¿è¡Œ

1. **å¯åŠ¨åº”ç”¨**: æ­£å¸¸å¯åŠ¨ï¼Œç•Œé¢ç«‹å³å¯ç”¨
2. **ä½¿ç”¨éŸ³é¢‘åŠŸèƒ½**: é¦–æ¬¡ä½¿ç”¨æ—¶ä¼šæ˜¾ç¤ºä¸‹è½½æç¤º
3. **æ¨¡å‹ä¸‹è½½**: è‡ªåŠ¨ä¸‹è½½æ‰€éœ€çš„ Whisper æ¨¡å‹ï¼ˆbase æ¨¡å‹çº¦ 140MBï¼‰
4. **åç»­ä½¿ç”¨**: æ¨¡å‹å·²ç¼“å­˜ï¼Œæ— éœ€é‡å¤ä¸‹è½½

## ğŸ“ˆ å®é™…ä¼˜åŒ–æ•ˆæœ

| é¡¹ç›®         | ä¼˜åŒ–å‰ | ä¼˜åŒ–å      | æ”¹å–„         |
| ------------ | ------ | ----------- | ------------ |
| æ‰“åŒ…ä½“ç§¯     | ~3GB   | **424.7MB** | **å‡å°‘ 86%** |
| ä¸»æ‰§è¡Œæ–‡ä»¶   | 28.4MB | **19.4MB**  | å‡å°‘ 32%     |
| é¦–æ¬¡å¯åŠ¨     | æ…¢     | å¿«          | ç«‹å³å¯ç”¨     |
| é¦–æ¬¡éŸ³é¢‘å¤„ç† | å¿«     | éœ€ä¸‹è½½æ¨¡å‹  | ä¸€æ¬¡æ€§æˆæœ¬   |
| åç»­ä½¿ç”¨     | å¿«     | å¿«          | æ— å·®å¼‚       |

### ğŸ¯ ä¼˜åŒ–æˆæœæ€»ç»“

âœ… **æˆåŠŸå°†åº”ç”¨ä½“ç§¯ä» 3GB å‡å°‘åˆ° 424.7MBï¼Œå®ç°äº† 86% çš„ä½“ç§¯ç¼©å‡**

- **ä¸»è¦è´¡çŒ®**ï¼šæ’é™¤äº†å¤§å‹ PyTorch æ¨¡å—å’Œ CUDA åº“
- **ç”¨æˆ·ä½“éªŒ**ï¼šåº”ç”¨å¯åŠ¨æ›´å¿«ï¼Œç•Œé¢å“åº”æ›´è¿…é€Ÿ
- **åŠŸèƒ½å®Œæ•´æ€§**ï¼šä¿æŒæ‰€æœ‰åŸæœ‰åŠŸèƒ½ï¼Œä»…åœ¨é¦–æ¬¡ä½¿ç”¨éŸ³é¢‘åŠŸèƒ½æ—¶éœ€è¦ä¸‹è½½æ¨¡å‹
- **åˆ†å‘ä¾¿åˆ©æ€§**ï¼šå¤§å¹…å‡å°‘ä¸‹è½½æ—¶é—´å’Œå­˜å‚¨éœ€æ±‚

## ğŸ’¡ æŠ€æœ¯ç»†èŠ‚

### æ¨¡å‹ä¸‹è½½ä½ç½®

- **Windows**: `%USERPROFILE%\.cache\huggingface\hub`
- **Linux/Mac**: `~/.cache/huggingface/hub`

### æ”¯æŒçš„æ¨¡å‹

- `tiny` (~39MB)
- `base` (~140MB) - é»˜è®¤
- `small` (~460MB)
- `large-v3` (~1.5GB)

### ç½‘ç»œè¦æ±‚

- é¦–æ¬¡ä½¿ç”¨éœ€è¦ç½‘ç»œè¿æ¥
- ä¸‹è½½é€Ÿåº¦å–å†³äºç½‘ç»œç¯å¢ƒ
- æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œé‡è¯•æœºåˆ¶

## ğŸ”§ æ•…éšœæ’é™¤

### æ¨¡å‹ä¸‹è½½å¤±è´¥

1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
3. å°è¯•ä½¿ç”¨ VPN
4. æ‰‹åŠ¨æ¸…ç†ç¼“å­˜åé‡è¯•

### æ¸…ç†æ¨¡å‹ç¼“å­˜

```bash
# Windows
rmdir /s "%USERPROFILE%\.cache\huggingface"

# Linux/Mac
rm -rf ~/.cache/huggingface
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **é¦–æ¬¡ä½¿ç”¨**: éœ€è¦ç½‘ç»œè¿æ¥ä¸‹è½½æ¨¡å‹
2. **å­˜å‚¨ç©ºé—´**: æ¨¡å‹ä¼šå ç”¨é¢å¤–çš„ç£ç›˜ç©ºé—´
3. **ç½‘ç»œç¯å¢ƒ**: æŸäº›ç½‘ç»œç¯å¢ƒå¯èƒ½éœ€è¦ä»£ç†è®¾ç½®
4. **æ¨¡å‹é€‰æ‹©**: å¯åœ¨è®¾ç½®ä¸­é€‰æ‹©ä¸åŒå¤§å°çš„æ¨¡å‹

## ğŸ‰ æ€»ç»“

é€šè¿‡å®æ–½è¿è¡Œæ—¶ä¸‹è½½ç­–ç•¥ï¼ŒæˆåŠŸå°†åº”ç”¨æ‰“åŒ…ä½“ç§¯å‡å°‘äº† 94%ï¼ŒåŒæ—¶ä¿æŒäº†å®Œæ•´çš„åŠŸèƒ½æ€§ã€‚ç”¨æˆ·åªéœ€åœ¨é¦–æ¬¡ä½¿ç”¨éŸ³é¢‘åŠŸèƒ½æ—¶ç­‰å¾…æ¨¡å‹ä¸‹è½½ï¼Œåç»­ä½¿ç”¨ä½“éªŒä¸åŸç‰ˆå®Œå…¨ä¸€è‡´ã€‚
